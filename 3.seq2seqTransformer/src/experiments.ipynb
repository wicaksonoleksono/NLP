{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/wicaksonolxn/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from dataloader import get_dataloaders\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from transformer import Transformer,TransformerEncoder,TransformerDecoder\n",
    "import utils\n",
    "import pickle\n",
    "nltk.download('punkt')  \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized on: cuda\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8 # butuh lebih banyak update \n",
    "DATA_PATH = \"dataset/\"  \n",
    "train_loader, val_loader, test_loader = get_dataloaders(\n",
    "    data_path=DATA_PATH, \n",
    "    source_lang=\"min\", \n",
    "    target_lang=\"eng\", \n",
    "    batch_size=BATCH_SIZE, \n",
    "    device=device\n",
    ")\n",
    "SRC_VOCAB_SIZE = 5000  \n",
    "TGT_VOCAB_SIZE = 5000  \n",
    "DROPOUT = 0.15      \n",
    "N_HEADS = 2\n",
    "N_LAYERS = 4       \n",
    "FFN_HIDDEN = 256      \n",
    "D_MODEL = 128        \n",
    "\n",
    "EPOCHS = 250\n",
    "SAVE_DIR = \"saved\"\n",
    "encoder = TransformerEncoder(SRC_VOCAB_SIZE,D_MODEL,N_LAYERS,N_HEADS,FFN_HIDDEN,DROPOUT,device)\n",
    "decoder = TransformerDecoder(TGT_VOCAB_SIZE,D_MODEL,N_LAYERS,N_HEADS,FFN_HIDDEN,DROPOUT,device)\n",
    "model = Transformer(encoder,decoder,device,utils.PAD_TOKEN).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=utils.PAD_TOKEN) \n",
    "print(\"Model initialized on:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 52]) tensor([  1,  55, 134, 987,  58,  47, 988, 989, 239, 126,  18,   7, 990, 991,\n",
      "         23, 992,  40,  93, 993,   8, 521,  27, 355, 987, 239, 994,  27,   2,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0])\n",
      "Padding: 0\n",
      "Start of Sequence: 1\n",
      "End of Sequence: 2\n",
      "Unknown: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wicaksonolxn/Documents/learnNLP/3.seq2seqTransformer/src/dataloader/_collate_fn.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  src_batch = [torch.tensor(item['src'], dtype=torch.long) for item in batch]\n",
      "/home/wicaksonolxn/Documents/learnNLP/3.seq2seqTransformer/src/dataloader/_collate_fn.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tgt_batch = [torch.tensor(item['tgt'], dtype=torch.long) for item in batch]\n"
     ]
    }
   ],
   "source": [
    "tokens = {\n",
    "    \"Padding\": utils.PAD_TOKEN,\n",
    "    \"Start of Sequence\": utils.SOS_TOKEN,\n",
    "    \"End of Sequence\": utils.EOS_TOKEN,\n",
    "    \"Unknown\": utils.UNK_TOKEN\n",
    "}\n",
    "for i, batch in enumerate(train_loader):\n",
    "    if i < 1:\n",
    "        src = batch[\"src\"]\n",
    "        tgt = batch[\"tgt\"]\n",
    "        ss,fss=src[0,:],src.shape\n",
    "        st,fst=tgt[0,:],tgt.shape\n",
    "        print(fss,ss)\n",
    "    for name, token in tokens.items():\n",
    "        print(f\"{name}: {token}\")\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing input , is it correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 431,    6,  456,   17,  542,   28, 1188,   22,  156, 1164,  174, 1189,\n",
      "          39, 1190,  416,  115,  840,  742,   61, 1191,   30,  282,   22,  471,\n",
      "          28,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,  376,  322,  161,  107,  226, 1382,   28,   10,  135,\n",
      "          70, 1383,   92, 1384,   39,   10,  135,   70, 1295,   36, 1385,    2,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,  241,  769,   31,   21,  623,   10,\n",
      "          73,  388, 1990,  524,  549, 1255, 1991,   73, 1992, 1993,  163,   22,\n",
      "         471,  132,   73,   94,  760,  760,  847,   28,   22, 1994, 1995,   39,\n",
      "          22, 1296,    6,   22, 1996, 1269,  115,  283, 1997,   76,   87, 1998,\n",
      "         858,  127,  132,   28,    2,    0,    0,    0,    0,   87,  263,   30,\n",
      "         520,   40,   10,  387,    8,  521,  522,   28,   72,   22,  269,   36,\n",
      "         523,   30,  264,  264,   39,  313,  271,  272,  524,  525,   28,  155,\n",
      "          61,   22,  526,  114,  161,  527,  127,  395,  146,  528,   28,   63,\n",
      "         338,  529,  355,  136,  269,  530,   28,    2,    0,    0,    0,    0,\n",
      "         155,   61,   22,  269,   63,   87,  141,  615,  226,   50,    2,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,   22,  269,   30,   38,   39,  438,  439,    6,  440,\n",
      "         441,  442,   28,  443,   72,   22,  444,  114,  270,   50,   39,   22,\n",
      "         263,   30,  445,  446,    6,  340,  305,   17,  244,   28,    2,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0, 1603,  216,  948,    6,  662, 1604,\n",
      "           8,  926,    8,  149, 1378, 1605,   22,  918, 1606,   28,    2,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,   22, 1943,  576,\n",
      "          28, 1944, 1945, 1946,   63,   22, 1947,   28,    2,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i,batch in enumerate(train_loader):\n",
    "    if i <1:\n",
    "        src_batch = batch['src'].to(device)\n",
    "        tgt_batch = batch['tgt'].to(device)\n",
    "        output, _ = model(src_batch, tgt_batch[:, :-1]) \n",
    "        output_dim = output.shape[-1]\n",
    "        output = output.reshape(-1, output_dim)\n",
    "        tgt_y = tgt_batch[:,1:].contiguous().view(-1)\n",
    "        print(tgt_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "        output,_= model(src_batch, tgt_batch)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, :-1, :].reshape(-1, output_dim)\n",
    "        tgt_y  = tgt_batch[:, 1:].reshape(-1)\n",
    "        pth = \"dataset\"\n",
    "src = \"min\"\n",
    "tgt = \"eng\"\n",
    "tp  = os.path.join(pth,f\"{src}_{tgt}\")\n",
    "input_dic_path = os.path.join(tp, \"input_dic.pkl\")\n",
    "output_dic_path = os.path.join(tp, \"output_dic.pkl\")\n",
    "with open(input_dic_path, \"rb\") as f:\n",
    "    inp = pickle.load(f)\n",
    "with open(output_dic_path, \"rb\") as f:\n",
    "    output_dictionary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 142.08it/s, loss=8.4913]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 8.5771 | Val Loss: 8.5268\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 2/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 169.74it/s, loss=8.1761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 8.2827 | Val Loss: 8.2291\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 3/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 146.11it/s, loss=7.9439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 8.0092 | Val Loss: 8.0026\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 4/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 164.01it/s, loss=7.7867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 7.8051 | Val Loss: 7.8457\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 5/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 112.15it/s, loss=7.6625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 7.6531 | Val Loss: 7.7196\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 6/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 169.47it/s, loss=7.5562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train Loss: 7.5204 | Val Loss: 7.6108\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 7/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 152.93it/s, loss=7.4625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train Loss: 7.4008 | Val Loss: 7.5158\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 8/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 167.54it/s, loss=7.3768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train Loss: 7.2898 | Val Loss: 7.4281\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 9/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 145.07it/s, loss=7.2972]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Loss: 7.1924 | Val Loss: 7.3490\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 10/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 167.05it/s, loss=7.2244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Train Loss: 7.0960 | Val Loss: 7.2755\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 11/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 137.71it/s, loss=7.1575]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Train Loss: 7.0068 | Val Loss: 7.2079\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 12/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 152.63it/s, loss=7.0965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Train Loss: 6.9244 | Val Loss: 7.1467\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 13/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 114.14it/s, loss=7.0401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Train Loss: 6.8500 | Val Loss: 7.0899\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 14/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 110.03it/s, loss=6.9882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Train Loss: 6.7736 | Val Loss: 7.0369\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 15/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 146.05it/s, loss=6.9417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Train Loss: 6.7080 | Val Loss: 6.9901\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 16/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 159.13it/s, loss=6.9007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] Train Loss: 6.6422 | Val Loss: 6.9484\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 17/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 153.76it/s, loss=6.8615]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] Train Loss: 6.5878 | Val Loss: 6.9092\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 18/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 181.00it/s, loss=6.8286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] Train Loss: 6.5327 | Val Loss: 6.8754\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 19/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 129.18it/s, loss=6.7999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] Train Loss: 6.4854 | Val Loss: 6.8456\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 20/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 183.52it/s, loss=6.7744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20] Train Loss: 6.4389 | Val Loss: 6.8201\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 21/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 142.91it/s, loss=6.7498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21] Train Loss: 6.3954 | Val Loss: 6.7949\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 22/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 107.61it/s, loss=6.7299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22] Train Loss: 6.3597 | Val Loss: 6.7745\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 23/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 100.19it/s, loss=6.7125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23] Train Loss: 6.3269 | Val Loss: 6.7570\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 24/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 133.71it/s, loss=6.6950]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24] Train Loss: 6.2943 | Val Loss: 6.7395\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 25/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 116.30it/s, loss=6.6809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25] Train Loss: 6.2627 | Val Loss: 6.7247\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 26/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 111.92it/s, loss=6.6674]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26] Train Loss: 6.2333 | Val Loss: 6.7117\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 27/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 130.27it/s, loss=6.6558]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27] Train Loss: 6.2139 | Val Loss: 6.6998\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 28/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 129.61it/s, loss=6.6474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28] Train Loss: 6.1907 | Val Loss: 6.6903\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 29/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 102.59it/s, loss=6.6402]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29] Train Loss: 6.1656 | Val Loss: 6.6825\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 30/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 133.04it/s, loss=6.6314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30] Train Loss: 6.1459 | Val Loss: 6.6736\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 31/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 133.48it/s, loss=6.6267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31] Train Loss: 6.1329 | Val Loss: 6.6678\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 32/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 125.84it/s, loss=6.6234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32] Train Loss: 6.1057 | Val Loss: 6.6637\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 33/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 134.53it/s, loss=6.6211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33] Train Loss: 6.0898 | Val Loss: 6.6592\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 34/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 175.14it/s, loss=6.6140]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34] Train Loss: 6.0747 | Val Loss: 6.6506\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 35/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 131.46it/s, loss=6.6138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 35] Train Loss: 6.0566 | Val Loss: 6.6481\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 36/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 179.16it/s, loss=6.6132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36] Train Loss: 6.0416 | Val Loss: 6.6454\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 37/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 153.31it/s, loss=6.6097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 37] Train Loss: 6.0269 | Val Loss: 6.6403\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 38/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 174.60it/s, loss=6.6083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38] Train Loss: 6.0170 | Val Loss: 6.6368\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 39/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 149.98it/s, loss=6.6064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 39] Train Loss: 5.9943 | Val Loss: 6.6313\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 40/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 180.25it/s, loss=6.6043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 40] Train Loss: 5.9853 | Val Loss: 6.6282\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 41/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 105.42it/s, loss=6.6016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 41] Train Loss: 5.9698 | Val Loss: 6.6220\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 42/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 161.27it/s, loss=6.5992]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 42] Train Loss: 5.9559 | Val Loss: 6.6191\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 43/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 105.85it/s, loss=6.5962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 43] Train Loss: 5.9410 | Val Loss: 6.6150\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 44/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 165.66it/s, loss=6.5942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 44] Train Loss: 5.9329 | Val Loss: 6.6124\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 45/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 108.44it/s, loss=6.5925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 45] Train Loss: 5.9190 | Val Loss: 6.6093\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 46/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 158.46it/s, loss=6.5852]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 46] Train Loss: 5.9028 | Val Loss: 6.6025\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 47/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 111.38it/s, loss=6.5857]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 47] Train Loss: 5.8928 | Val Loss: 6.6003\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 48/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 126.74it/s, loss=6.5851]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 48] Train Loss: 5.8801 | Val Loss: 6.5995\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 49/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 104.93it/s, loss=6.5840]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 49] Train Loss: 5.8685 | Val Loss: 6.5978\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 50/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 125.65it/s, loss=6.5808]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 50] Train Loss: 5.8582 | Val Loss: 6.5938\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 51/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 123.67it/s, loss=6.5737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 51] Train Loss: 5.8461 | Val Loss: 6.5868\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 52/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 173.11it/s, loss=6.5761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 52] Train Loss: 5.8309 | Val Loss: 6.5903\n",
      "Epoch 53/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 96.04it/s, loss=6.5769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 53] Train Loss: 5.8219 | Val Loss: 6.5898\n",
      "Epoch 54/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 120.63it/s, loss=6.5712]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 54] Train Loss: 5.8140 | Val Loss: 6.5831\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 55/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 117.67it/s, loss=6.5708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 55] Train Loss: 5.7958 | Val Loss: 6.5834\n",
      "Epoch 56/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 145.59it/s, loss=6.5689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 56] Train Loss: 5.7916 | Val Loss: 6.5818\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 57/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 111.52it/s, loss=6.5679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 57] Train Loss: 5.7703 | Val Loss: 6.5801\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 58/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 121.50it/s, loss=6.5655]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 58] Train Loss: 5.7617 | Val Loss: 6.5788\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 59/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 94.80it/s, loss=6.5614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 59] Train Loss: 5.7442 | Val Loss: 6.5743\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 60/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 116.93it/s, loss=6.5587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 60] Train Loss: 5.7359 | Val Loss: 6.5712\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 61/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 99.96it/s, loss=6.5562] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 61] Train Loss: 5.7269 | Val Loss: 6.5704\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 62/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 119.08it/s, loss=6.5595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 62] Train Loss: 5.7159 | Val Loss: 6.5742\n",
      "Epoch 63/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 121.07it/s, loss=6.5548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 63] Train Loss: 5.7040 | Val Loss: 6.5694\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 64/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 134.42it/s, loss=6.5562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 64] Train Loss: 5.6920 | Val Loss: 6.5691\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 65/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 127.76it/s, loss=6.5500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 65] Train Loss: 5.6822 | Val Loss: 6.5652\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 66/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 148.67it/s, loss=6.5493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 66] Train Loss: 5.6736 | Val Loss: 6.5653\n",
      "Epoch 67/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 147.51it/s, loss=6.5461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 67] Train Loss: 5.6534 | Val Loss: 6.5632\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 68/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 132.70it/s, loss=6.5463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 68] Train Loss: 5.6412 | Val Loss: 6.5636\n",
      "Epoch 69/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 122.70it/s, loss=6.5422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 69] Train Loss: 5.6367 | Val Loss: 6.5610\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 70/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 138.64it/s, loss=6.5448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 70] Train Loss: 5.6255 | Val Loss: 6.5623\n",
      "Epoch 71/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 103.28it/s, loss=6.5419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 71] Train Loss: 5.6090 | Val Loss: 6.5607\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 72/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 171.01it/s, loss=6.5510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 72] Train Loss: 5.6045 | Val Loss: 6.5672\n",
      "Epoch 73/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 132.46it/s, loss=6.5459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 73] Train Loss: 5.5908 | Val Loss: 6.5636\n",
      "Epoch 74/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 145.52it/s, loss=6.5404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 74] Train Loss: 5.5804 | Val Loss: 6.5588\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 75/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 82.82it/s, loss=6.5408]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 75] Train Loss: 5.5652 | Val Loss: 6.5606\n",
      "Epoch 76/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 117.43it/s, loss=6.5351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 76] Train Loss: 5.5509 | Val Loss: 6.5558\n",
      "  -> New best model saved at saved/best.pt\n",
      "Epoch 77/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸš€ Training:   0%|          | 0/102 [00:00<?, ?it/s, loss=5.2665]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "best_val_loss = float(\"inf\")\n",
    "best_model_path = None\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f\"Epoch {epoch}/{EPOCHS}\")\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    train_bar = tqdm(train_loader, desc=\"ðŸš€ Training\", \n",
    "                leave=False, total=len(train_loader))\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        src_batch = batch['src'].to(device)\n",
    "        tgt_batch = batch['tgt'].to(device)\n",
    "        \n",
    "        output, _ = model(src_batch, tgt_batch[:, :-1]) \n",
    "        output_dim = output.shape[-1]\n",
    "        output = output.reshape(-1, output_dim)\n",
    "        tgt_y = tgt_batch[:,1:].contiguous().view(-1)\n",
    "\n",
    "        loss = criterion(output, tgt_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "        train_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    val_bar = tqdm(val_loader, desc=\"ðŸš€ Validation\",\n",
    "              leave=True, total=len(val_loader))\n",
    "    with torch.no_grad():\n",
    "        for batch in val_bar:\n",
    "            src_batch = batch['src'].to(device)\n",
    "            tgt_batch = batch['tgt'].to(device)\n",
    "            \n",
    "            output, _ = model(src_batch, tgt_batch[:, :-1]) \n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.reshape(-1, output_dim)\n",
    "            tgt_y = tgt_batch[:,1:].contiguous().view(-1)\n",
    "\n",
    "            loss = criterion(output, tgt_y)\n",
    "            total_val_loss += loss.item()\n",
    "            val_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    print(f\"[Epoch {epoch}] Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        if best_model_path and os.path.exists(best_model_path):\n",
    "            os.remove(best_model_path)\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_model_path = os.path.join(SAVE_DIR, \"best.pt\")\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"  -> New best model saved at {best_model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bleu Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the best model !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model for testing!\n",
      "Validation Loss = 8.7341 | BLEU = 89.00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "SRC_VOCAB_SIZE = 5000  \n",
    "TGT_VOCAB_SIZE = 5000  \n",
    "DROPOUT = 0.15      \n",
    "N_HEADS = 2\n",
    "N_LAYERS = 4       \n",
    "FFN_HIDDEN = 256      \n",
    "D_MODEL = 128    \n",
    "encoder = TransformerEncoder(SRC_VOCAB_SIZE, D_MODEL, N_LAYERS, N_HEADS, FFN_HIDDEN, DROPOUT, device)\n",
    "decoder = TransformerDecoder(TGT_VOCAB_SIZE, D_MODEL, N_LAYERS, N_HEADS, FFN_HIDDEN, DROPOUT, device)\n",
    "best_model = Transformer(encoder, decoder, device, utils.PAD_TOKEN).to(device)\n",
    "best_model.load_state_dict(torch.load(os.path.join(SAVE_DIR, \"best.pt\")))\n",
    "print(\"Loaded best model for testing!\")\n",
    "pth = \"dataset\"\n",
    "src = \"min\"\n",
    "tgt = \"eng\"\n",
    "tp  = os.path.join(pth, f\"{src}_{tgt}\")\n",
    "with open(os.path.join(tp, \"input_dic.pkl\"),  \"rb\") as f:\n",
    "    input_lang_dic = pickle.load(f)\n",
    "with open(os.path.join(tp, \"output_dic.pkl\"), \"rb\") as f:\n",
    "    output_lang_dic = pickle.load(f)\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) Evaluate function\n",
    "# ---------------------------------------------------------------------\n",
    "def evaluate(model, valid_dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    all_bleu   = []\n",
    "    with torch.no_grad():\n",
    "        for batch_num, batch in enumerate(valid_dataloader):\n",
    "            src_batch = batch[\"src\"].to(device)\n",
    "            tgt_batch = batch[\"tgt\"].to(device)\n",
    "            output, _ = model(src_batch, tgt_batch[:, :-1])\n",
    "            out_dim = output.size(-1)  \n",
    "            output_2d = output.contiguous().view(-1, out_dim)\n",
    "            tgt_2d = tgt_batch[:, 1:].contiguous().view(-1)\n",
    "            \n",
    "            loss = criterion(output_2d, tgt_2d)\n",
    "            total_loss += loss.item()\n",
    "            batch_size = src_batch.size(0)\n",
    "            batch_bleu = []\n",
    "            for i in range(batch_size):\n",
    "                ref_tokens = utils.detokenize(tgt_batch[i].tolist(), output_lang_dic)\n",
    "                pred_ids   = output[i].argmax(dim=1)  # shape [seq_len-1]\n",
    "                hyp_tokens = utils.detokenize(pred_ids.tolist(), output_lang_dic)\n",
    "                bleu_score = utils.get_bleu(hyp_tokens.split(), ref_tokens.split())\n",
    "                batch_bleu.append(bleu_score)\n",
    "            all_bleu.append(sum(batch_bleu) / len(batch_bleu))\n",
    "    epoch_loss = total_loss / len(valid_dataloader)\n",
    "    epoch_bleu = sum(all_bleu) / len(all_bleu)\n",
    "    return epoch_loss, epoch_bleu\n",
    "valid_loss, valid_bleu = evaluate(best_model, val_loader)\n",
    "print(f\"Validation Loss = {valid_loss:.4f} | BLEU = {valid_bleu:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source tokens: [1, 3, 573, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Decoded tokens: ['SOS', 'UNK', 'mancari', 'UNK', 'UNK', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "Original: Ambo mancari awaknyo besok\n",
      "Translated: \n",
      "\n",
      "Source tokens: [1, 3, 3, 425, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Decoded tokens: ['SOS', 'UNK', 'UNK', 'apo', 'UNK', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "Original: Alun salama, apo kabar?\n",
      "Translated: \n",
      "\n",
      "Source tokens: [1, 3, 134, 64, 514, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Decoded tokens: ['SOS', 'UNK', 'ka', 'rumah', 'gadang', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "Original: Dunsanak ka rumah gadang\n",
      "Translated: \n",
      "\n",
      "Source tokens: [1, 3, 3, 659, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Decoded tokens: ['SOS', 'UNK', 'UNK', 'manarimo', 'UNK', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "Original: Urang minang manarimo tradisi\n",
      "Translated: \n",
      "\n",
      "Source tokens: [1, 3, 126, 47, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Decoded tokens: ['SOS', 'UNK', 'ado', 'di', 'UNK', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "Original: Apo ado di pasar?\n",
      "Translated: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from utils import tokenize,detokenize\n",
    "import torch\n",
    "import utils  # For PAD_TOKEN, SOS_TOKEN, EOS_TOKEN, UNK_TOKEN, etc.\n",
    "def translate_sentence(token_ids,input_dic, output_dic, model, device, max_len=50):\n",
    "    model.eval()\n",
    "    \n",
    "    input_tensor = torch.LongTensor(token_ids).unsqueeze(0).to(device)\n",
    "    src_mask = model.make_input_mask(input_tensor)\n",
    "    \n",
    "    print(\"Source tokens:\", token_ids)\n",
    "    print(\"Decoded tokens:\", [input_dic.index2word[x] for x in token_ids])\n",
    "    with torch.no_grad():\n",
    "        encoded_input = model.encoder(input_tensor, src_mask)\n",
    "    predicted_tokens = [utils.SOS_TOKEN]\n",
    "    for _ in range(max_len):\n",
    "        tgt_tensor = torch.LongTensor(predicted_tokens).unsqueeze(0).to(device)\n",
    "        tgt_mask = model.make_target_mask(tgt_tensor)\n",
    "        with torch.no_grad():\n",
    "            output, attention = model.decoder(tgt_tensor, encoded_input, tgt_mask, src_mask)\n",
    "        next_token = output[0, -1].argmax(dim=-1).item()\n",
    "        predicted_tokens.append(next_token)\n",
    "        \n",
    "        if next_token == utils.EOS_TOKEN:\n",
    "            break\n",
    "    translation = ' '.join(output_dic.index2word[idx] \n",
    "                           for idx in predicted_tokens[1:] \n",
    "                           if idx not in [utils.SOS_TOKEN, utils.EOS_TOKEN, utils.PAD_TOKEN])\n",
    "    return translation\n",
    "sentences = [\n",
    "    \"Ambo mancari awaknyo besok\",\n",
    "    \"Alun salama, apo kabar?\",\n",
    "    \"Dunsanak ka rumah gadang\",\n",
    "    \"Urang minang manarimo tradisi\",\n",
    "    \"Apo ado di pasar?\"\n",
    "]\n",
    "tokenized_inputs = []\n",
    "for s in sentences:\n",
    "    tokens = utils.tokenize(s, input_lang_dic, utils.MAX_SENT_LEN)\n",
    "    tokenized_inputs.append(tokens)\n",
    "    \n",
    "for idx, token_ids in enumerate(tokenized_inputs):\n",
    "    translation = translate_sentence(\n",
    "        token_ids,\n",
    "        input_lang_dic,\n",
    "        output_lang_dic,\n",
    "        best_model,\n",
    "        device,\n",
    "        utils.MAX_SENT_LEN\n",
    "    )\n",
    "    print(f\"Original: {sentences[idx]}\")\n",
    "    print(f\"Translated: {translation}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index to word mapping (first 10):\n",
      "0 PAD\n",
      "1 SOS\n",
      "2 EOS\n",
      "3 UNK\n",
      "4 enjoy\n",
      "5 instalment\n",
      "6 for\n",
      "7 up\n",
      "8 to\n",
      "9 months\n"
     ]
    }
   ],
   "source": [
    "print(\"Index to word mapping (first 10):\")\n",
    "for i in range(10):\n",
    "    print(i, output_lang_dic.index2word[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary size: 2183\n",
      "Special tokens in the dictionary:\n",
      "0 PAD\n",
      "1 SOS\n",
      "2 EOS\n",
      "3 nikmati\n"
     ]
    }
   ],
   "source": [
    "print(\"Dictionary size:\", len(input_lang_dic.word2index))\n",
    "print(\"Special tokens in the dictionary:\")\n",
    "for idx in range(4):\n",
    "    print(idx, input_lang_dic.index2word[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.word_embedding.weight torch.Size([5000, 128])\n",
      "decoder.word_embedding.weight torch.Size([5000, 128])\n"
     ]
    }
   ],
   "source": [
    "for name, param in best_model.named_parameters():\n",
    "    if \"word_embedding\" in name:\n",
    "        print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pickle\n",
    "# import torch\n",
    "\n",
    "# from utils import tokenize,detokenize\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# # -----------------------------------------------------------------------------\n",
    "# # 1. Load the best model for testing\n",
    "# # -----------------------------------------------------------------------------\n",
    "\n",
    "# # Create encoder, decoder, and the full Transformer model.\n",
    "# encoder = TransformerEncoder(SRC_VOCAB_SIZE, D_MODEL, N_LAYERS, N_HEADS, FFN_HIDDEN, DROPOUT, device)\n",
    "# decoder = TransformerDecoder(TGT_VOCAB_SIZE, D_MODEL, N_LAYERS, N_HEADS, FFN_HIDDEN, DROPOUT, device)\n",
    "# best_model = Transformer(encoder, decoder, device, utils.PAD_TOKEN).to(device)\n",
    "\n",
    "# # Load the best model state\n",
    "# model_path = os.path.join(SAVE_DIR, \"best.pt\")\n",
    "# best_model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "# print(\"Loaded best model for testing!\")\n",
    "# # -----------------------------------------------------------------------------\n",
    "# # 2. Load the input and output dictionaries\n",
    "# # -----------------------------------------------------------------------------\n",
    "# pth = \"dataset\"\n",
    "# src = \"min\"\n",
    "# tgt = \"eng\"\n",
    "# tp  = os.path.join(pth,f\"{src}_{tgt}\")\n",
    "# input_dic_path = os.path.join(tp, \"input_dic.pkl\")\n",
    "# output_dic_path = os.path.join(tp, \"output_dic.pkl\")\n",
    "# with open(input_dic_path, \"rb\") as f:\n",
    "#     input_dictionary = pickle.load(f)\n",
    "# with open(output_dic_path, \"rb\") as f:\n",
    "#     output_dictionary = pickle.load(f)\n",
    "\n",
    "# minang_sentences = [\n",
    "#     \"Ambo mancari awaknyo besok\",\n",
    "#     \"Alun salama, apo kabar?\",\n",
    "#     \"Dunsanak ka rumah gadang\",\n",
    "#     \"Urang minang manarimo tradisi\",\n",
    "#     \"Apo ado di pasar?\"\n",
    "# ]\n",
    "\n",
    "# for sentence in minang_sentences:\n",
    "#     translation = translate_sentence(sentence, best_model, input_dictionary, output_dictionary)\n",
    "#     print(f\"Original:   {sentence}\")\n",
    "#     print(f\"Translated: {translation}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translasi: \n",
    "Ambo mancari awaknyo besok\n",
    "\n",
    "    Bahasa Indonesia: Saya akan mencarimu besok.\n",
    "    English: I will look for you tomorrow.\n",
    "\n",
    "Alun salama, apo kabar?\n",
    "\n",
    "    Bahasa Indonesia: Halo, apa kabar?\n",
    "    English: Hello, how are you?\n",
    "\n",
    "Dunsanak ka rumah gadang\n",
    "\n",
    "    Bahasa Indonesia: Saudara, mari ke rumah gadang.\n",
    "    English: Relatives, let's go to the traditional house.\n",
    "\n",
    "Urang minang manarimo tradisi\n",
    "\n",
    "    Bahasa Indonesia: Orang Minang menerima tradisi.\n",
    "    English: Minangkabau people embrace tradition.\n",
    "\n",
    "Apo ado di pasar?\n",
    "\n",
    "    Bahasa Indonesia: Apa ada di pasar?\n",
    "    English: What's there in the market?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
